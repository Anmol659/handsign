{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d31c69-b46f-49d5-af66-a638ac97dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handLms in result.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Hand Tracking\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5516bc46-73c6-4efa-bcb6-1e880e3b5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handLms in result.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # Get the landmarks for the thumb\n",
    "            thumb_tip = handLms.landmark[4]\n",
    "            thumb_base = handLms.landmark[2]\n",
    "\n",
    "            # Check if the thumb is pointing up (tip is above the base)\n",
    "            if thumb_tip.y < thumb_base.y:\n",
    "                cv2.putText(img, \"Thumb Up Detected\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Hand Tracking\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32aa8bfd-4faa-4806-9c6a-0e58b605df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess  # To open applications\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize mediapipe hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Path to your app (example: opening Chrome browser)\n",
    "app_path = \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handLms in result.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get the landmarks for the thumb\n",
    "            thumb_tip = handLms.landmark[4]\n",
    "            thumb_base = handLms.landmark[2]\n",
    "\n",
    "            # Check if the thumb is pointing up (thumb tip is above the base)\n",
    "            if thumb_tip.y < thumb_base.y:\n",
    "                cv2.putText(img, \"Thumb Up Detected\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Trigger app launch (if thumb-up is detected)\n",
    "                subprocess.Popen([app_path])  # This will open the app\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Hand Tracking\", img)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5781ff09-b3a7-450a-b530-288b18b4007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "from tkinter import *\n",
    "import threading\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define gesture -> app mapping\n",
    "GESTURE_ACTIONS = {\n",
    "    \"fist\": \"notepad\",     # Fist will open Notepad\n",
    "    \"peace\": \"calc\",       # Peace sign will open Calculator\n",
    "}\n",
    "\n",
    "def detect_gesture(landmarks):\n",
    "    # Very simple gesture recognition using landmark distance\n",
    "    thumb_tip = landmarks[4]\n",
    "    index_tip = landmarks[8]\n",
    "    middle_tip = landmarks[12]\n",
    "\n",
    "    if abs(index_tip.y - middle_tip.y) < 0.02:\n",
    "        return \"peace\"\n",
    "    elif abs(index_tip.y - thumb_tip.y) < 0.02:\n",
    "        return \"fist\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def run_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process hand landmarks\n",
    "        result = hands.process(rgb)\n",
    "        gesture = None\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            \n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = detect_gesture(hand_landmarks.landmark)\n",
    "\n",
    "        # Display gesture and open app\n",
    "        if gesture:\n",
    "            cv2.putText(frame, f\"Gesture: {gesture}\", (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            if gesture in GESTURE_ACTIONS:\n",
    "                subprocess.Popen(GESTURE_ACTIONS[gesture], shell=True)\n",
    "\n",
    "        cv2.imshow(\"Hand Sign Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8386622-a978-44c0-b6ee-a2d1d2f2ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_detection():\n",
    "    threading.Thread(target=run_camera).start()\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Hand Sign App Launcher\")\n",
    "\n",
    "label = Label(root, text=\"Click to Start Gesture Detection\", font=(\"Arial\", 16))\n",
    "label.pack(pady=20)\n",
    "\n",
    "start_button = Button(root, text=\"Start\", command=start_detection, font=(\"Arial\", 14))\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c4beb-0c62-4240-9a97-4101eb186d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching thumbs_up → mspaint\n",
      "Gesture 'thumbs_up' is on cooldown.\n",
      "Gesture 'thumbs_up' is on cooldown.\n",
      "Gesture 'thumbs_up' is on cooldown.\n",
      "Launching palm → C:/Program Files/Google/Chrome/Application/chrome.exe\n",
      "Gesture 'thumbs_up' is on cooldown.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "from tkinter import *\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Gesture-to-app mapping\n",
    "GESTURE_ACTIONS = {\n",
    "    \"fist\": \"notepad\",\n",
    "    \"peace\": \"calc\",\n",
    "    \"palm\": \"C:/Program Files/Google/Chrome/Application/chrome.exe\",\n",
    "    \"thumbs_up\": \"mspaint\",\n",
    "    \"ok_sign\": \"explorer\"\n",
    "}\n",
    "\n",
    "# Cooldown tracking (seconds)\n",
    "last_launched = {gesture: 0 for gesture in GESTURE_ACTIONS}\n",
    "COOLDOWN_SECONDS = 10  # Prevent repeat within 10 seconds\n",
    "\n",
    "# Detect gesture using hand landmarks\n",
    "def detect_gesture(landmarks):\n",
    "    tips = [landmarks[i] for i in [4, 8, 12, 16, 20]]  # Thumb to pinky tips\n",
    "    bases = [landmarks[i] for i in [3, 6, 10, 14, 18]] # Finger bases\n",
    "\n",
    "    def is_up(tip, base):\n",
    "        return tip.y < base.y\n",
    "\n",
    "    fingers = [is_up(tips[i], bases[i]) for i in range(5)]\n",
    "\n",
    "    if fingers == [False, False, False, False, False]:\n",
    "        return \"fist\"\n",
    "    elif fingers == [False, True, True, False, False]:\n",
    "        return \"peace\"\n",
    "    elif fingers == [True, True, True, True, True]:\n",
    "        return \"palm\"\n",
    "    elif fingers == [True, False, False, False, False]:\n",
    "        return \"thumbs_up\"\n",
    "    elif fingers[0] and fingers[1] and abs(landmarks[4].x - landmarks[8].x) < 0.05:\n",
    "        return \"ok_sign\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Camera + gesture detection\n",
    "def run_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_gesture = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        gesture = None\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = detect_gesture(hand_landmarks.landmark)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if gesture and gesture != last_gesture:\n",
    "            last_gesture = gesture\n",
    "            if gesture in GESTURE_ACTIONS:\n",
    "                if current_time - last_launched[gesture] > COOLDOWN_SECONDS:\n",
    "                    print(f\"Launching {gesture} → {GESTURE_ACTIONS[gesture]}\")\n",
    "                    subprocess.Popen(GESTURE_ACTIONS[gesture], shell=True)\n",
    "                    last_launched[gesture] = current_time\n",
    "                else:\n",
    "                    print(f\"Gesture '{gesture}' is on cooldown.\")\n",
    "        elif gesture is None:\n",
    "            last_gesture = None\n",
    "\n",
    "        cv2.putText(frame, f\"Gesture: {gesture or 'None'}\", (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Sign Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI\n",
    "def start_detection():\n",
    "    threading.Thread(target=run_camera).start()\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Hand Sign App Launcher\")\n",
    "root.geometry(\"400x200\")\n",
    "\n",
    "label = Label(root, text=\"Click to Start Gesture Recognition\", font=(\"Arial\", 14))\n",
    "label.pack(pady=20)\n",
    "\n",
    "start_button = Button(root, text=\"Start\", command=start_detection, font=(\"Arial\", 14), bg=\"green\", fg=\"white\")\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba2657-a8d3-4ac0-823b-aef4ebb5f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching thumbs_up → C:\\Games\\Forza Horizon 5\\Forza Horizon5.exe\n",
      "Gesture 'thumbs_up' is on cooldown.\n",
      "Launching fist → C:\\Games\\Adobe Premiere Pro 2025\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "from tkinter import *\n",
    "import threading\n",
    "import time\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Gesture-to-app mapping\n",
    "GESTURE_ACTIONS = {\n",
    "    \"fist\": \"C:\\Games\\Adobe Premiere Pro 2025\",\n",
    "    \"peace\": \"calc\",\n",
    "    \"palm\": \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "    \"thumbs_up\": \"C:\\Games\\Forza Horizon 5\\Forza Horizon5.exe\",\n",
    "    \"ok_sign\": \"explorer\"\n",
    "}\n",
    "\n",
    "# Cooldown tracking (seconds)\n",
    "last_launched = {gesture: 0 for gesture in GESTURE_ACTIONS}\n",
    "COOLDOWN_SECONDS = 10  # Prevent repeat within 10 seconds\n",
    "\n",
    "# Detect gesture using hand landmarks\n",
    "def detect_gesture(landmarks):\n",
    "    tips = [landmarks[i] for i in [4, 8, 12, 16, 20]]  # Thumb to pinky tips\n",
    "    bases = [landmarks[i] for i in [3, 6, 10, 14, 18]] # Finger bases\n",
    "\n",
    "    def is_up(tip, base):\n",
    "        return tip.y < base.y\n",
    "\n",
    "    fingers = [is_up(tips[i], bases[i]) for i in range(5)]\n",
    "\n",
    "    if fingers == [False, False, False, False, False]:\n",
    "        return \"fist\"\n",
    "    elif fingers == [False, True, True, False, False]:\n",
    "        return \"peace\"\n",
    "    elif fingers == [True, True, True, True, True]:\n",
    "        return \"palm\"\n",
    "    elif fingers == [True, False, False, False, False]:\n",
    "        return \"thumbs_up\"\n",
    "    elif fingers[0] and fingers[1] and abs(landmarks[4].x - landmarks[8].x) < 0.05:\n",
    "        return \"ok_sign\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Camera + gesture detection\n",
    "def run_camera(canvas, window):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    last_gesture = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        gesture = None\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = detect_gesture(hand_landmarks.landmark)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if gesture and gesture != last_gesture:\n",
    "            last_gesture = gesture\n",
    "            if gesture in GESTURE_ACTIONS:\n",
    "                if current_time - last_launched[gesture] > COOLDOWN_SECONDS:\n",
    "                    print(f\"Launching {gesture} → {GESTURE_ACTIONS[gesture]}\")\n",
    "                    subprocess.Popen(GESTURE_ACTIONS[gesture], shell=True)\n",
    "                    last_launched[gesture] = current_time\n",
    "                else:\n",
    "                    print(f\"Gesture '{gesture}' is on cooldown.\")\n",
    "        elif gesture is None:\n",
    "            last_gesture = None\n",
    "\n",
    "        # Convert the frame to Tkinter format and display it on the canvas\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert color for display\n",
    "        img = Image.fromarray(frame)  # Convert to PIL Image\n",
    "        img_tk = ImageTk.PhotoImage(image=img)  # Convert to ImageTk format\n",
    "\n",
    "        # Update the canvas with the new image\n",
    "        canvas.create_image(0, 0, anchor=NW, image=img_tk)\n",
    "        window.update_idletasks()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# GUI Setup\n",
    "def start_detection():\n",
    "    threading.Thread(target=run_camera, args=(canvas, window), daemon=True).start()\n",
    "\n",
    "# Tkinter GUI\n",
    "window = Tk()\n",
    "window.title(\"Hand Sign App Launcher\")\n",
    "window.geometry(\"1280x720\")  # Make window larger\n",
    "\n",
    "label = Label(window, text=\"Click to Start Gesture Recognition\", font=(\"Arial\", 20))\n",
    "label.pack(pady=30)\n",
    "\n",
    "start_button = Button(window, text=\"Start\", command=start_detection, font=(\"Arial\", 18), bg=\"green\", fg=\"white\", width=15, height=2)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "# Create a canvas to display the camera feed\n",
    "canvas = Canvas(window, width=1280, height=720)\n",
    "canvas.pack()\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6a63c1-13b6-4bc6-a613-8c89573a3883",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: expecting '}' (4164053277.py, line 101)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 101\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"Launching {\"C:/Games/Adobe Premiere Pro 2025/Adobe Premiere Pro.exe\"}\")\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: expecting '}'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "from tkinter import *\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Gesture-to-app mapping with corrected paths\n",
    "GESTURE_ACTIONS = {\n",
    "    \"fist\": r\"C:/Games/Adobe Premiere Pro 2025/Adobe Premiere Pro.exe\",\n",
    "    \"victory\": \"calc\",  # Using simple app for testing\n",
    "    \"palm\": r\"C:/Program Files/Google/Chrome/Application/chrome.exe\",\n",
    "    \"thumbs_up\": r\"C:/Games/Forza Horizon 5/Forza Horizon5.exe\",\n",
    "    \"rock_on\": \"explorer\"\n",
    "}\n",
    "\n",
    "# Cooldown tracking (seconds)\n",
    "last_launched = {gesture: 0 for gesture in GESTURE_ACTIONS}\n",
    "COOLDOWN_SECONDS = 10  # Prevent repeat within 10 seconds\n",
    "\n",
    "# Variable to control the camera loop\n",
    "camera_running = False\n",
    "\n",
    "# Detect gesture using hand landmarks\n",
    "def detect_gesture(landmarks):\n",
    "    tips = [landmarks[i] for i in [4, 8, 12, 16, 20]]  # Thumb to pinky tips\n",
    "    bases = [landmarks[i] for i in [3, 6, 10, 14, 18]] # Finger bases\n",
    "\n",
    "    def is_up(tip, base):\n",
    "        return tip.y < base.y\n",
    "\n",
    "    fingers = [is_up(tips[i], bases[i]) for i in range(5)]\n",
    "\n",
    "    if fingers == [False, False, False, False, False]:\n",
    "        return \"fist\"\n",
    "    elif fingers == [False, True, True, False, False]:\n",
    "        return \"victory\"\n",
    "    elif fingers == [True, True, True, True, True]:\n",
    "        return \"palm\"\n",
    "    elif fingers == [True, False, False, False, False]:\n",
    "        return \"thumbs_up\"\n",
    "    elif fingers[0] and fingers[1] and abs(landmarks[4].x - landmarks[8].x) < 0.05:\n",
    "        return \"rock_on\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Camera + gesture detection\n",
    "def run_camera():\n",
    "    global camera_running\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_gesture = None\n",
    "\n",
    "    while camera_running:  # Loop will run while camera_running is True\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        gesture = None\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = detect_gesture(hand_landmarks.landmark)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if gesture and gesture != last_gesture:\n",
    "            last_gesture = gesture\n",
    "            if gesture in GESTURE_ACTIONS:\n",
    "                if current_time - last_launched[gesture] > COOLDOWN_SECONDS:\n",
    "                    print(f\"Launching {gesture} → {GESTURE_ACTIONS[gesture]}\")\n",
    "                    launch_app(GESTURE_ACTIONS[gesture])\n",
    "                    last_launched[gesture] = current_time\n",
    "                else:\n",
    "                    print(f\"Gesture '{gesture}' is on cooldown.\")\n",
    "        elif gesture is None:\n",
    "            last_gesture = None\n",
    "\n",
    "        cv2.putText(frame, f\"Gesture: {gesture or 'None'}\", (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Sign Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Break if 'Esc' key is pressed\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Launch application\n",
    "def launch_app(app_path):\n",
    "    try:\n",
    "        subprocess.Popen(\"C:/Games/Adobe Premiere Pro 2025/Adobe Premiere Pro.exe\", shell=True)\n",
    "        print(f\"Launching {\"C:/Games/Adobe Premiere Pro 2025/Adobe Premiere Pro.exe\"}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error launching {\"C:/Games/Forza Horizon 5/Forza Horizon5.exe\"}: {e}\")\n",
    "\n",
    "# Start camera detection\n",
    "def start_detection():\n",
    "    global camera_running\n",
    "    camera_running = True  # Set flag to True to start camera\n",
    "    threading.Thread(target=run_camera, daemon=True).start()\n",
    "\n",
    "# Stop camera detection\n",
    "def stop_detection():\n",
    "    global camera_running\n",
    "    camera_running = False  # Set flag to False to stop camera\n",
    "    print(\"Camera stopped.\")\n",
    "\n",
    "# GUI\n",
    "root = Tk()\n",
    "root.title(\"Hand Sign App Launcher\")\n",
    "root.geometry(\"400x200\")\n",
    "\n",
    "label = Label(root, text=\"Click to Start Gesture Recognition\", font=(\"Arial\", 14))\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Start Button\n",
    "start_button = Button(root, text=\"Start\", command=start_detection, font=(\"Arial\", 14), bg=\"green\", fg=\"white\")\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "# Stop Button\n",
    "stop_button = Button(root, text=\"Stop\", command=stop_detection, font=(\"Arial\", 14), bg=\"red\", fg=\"white\")\n",
    "stop_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a73428e-883d-4e19-a2aa-10b8681ebf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected gesture: palm\n",
      "Launching C:/Program Files/Google/Chrome/Application/chrome.exe\n",
      "Detected gesture: rock_on\n",
      "Launching explorer\n",
      "Gesture 'rock_on' is on cooldown.\n",
      "Gesture 'rock_on' is on cooldown.\n",
      "Gesture 'rock_on' is on cooldown.\n",
      "Gesture 'rock_on' is on cooldown.\n",
      "Detected gesture: rock_on\n",
      "Launching explorer\n",
      "Gesture 'rock_on' is on cooldown.\n",
      "Detected gesture: thumbs_up\n",
      "Launching C:\\Games\\Clair Obscur - Expedition 33\\Expedition33_Steam.exe\n",
      "Camera stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "from tkinter import *\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Gesture-to-app mapping with corrected paths\n",
    "GESTURE_ACTIONS = {\n",
    "    \"fist\": r\"C:/Games/Adobe Premiere Pro 2025/Adobe Premiere Pro.exe\",\n",
    "    \"victory\": \"calc\",  # Calculator for testing\n",
    "    \"palm\": r\"C:/Program Files/Google/Chrome/Application/chrome.exe\",\n",
    "    \"thumbs_up\": r\"C:\\Games\\Clair Obscur - Expedition 33\\Expedition33_Steam.exe\",\n",
    "    \"rock_on\": \"explorer\"\n",
    "}\n",
    "\n",
    "# Cooldown tracking (seconds)\n",
    "last_launched = {gesture: 0 for gesture in GESTURE_ACTIONS}\n",
    "COOLDOWN_SECONDS = 10  # Prevent repeat within 10 seconds\n",
    "\n",
    "# Variable to control the camera loop\n",
    "camera_running = False\n",
    "\n",
    "# Detect gesture using hand landmarks\n",
    "def detect_gesture(landmarks):\n",
    "    tips = [landmarks[i] for i in [4, 8, 12, 16, 20]]  # Thumb to pinky tips\n",
    "    bases = [landmarks[i] for i in [3, 6, 10, 14, 18]]  # Finger bases\n",
    "\n",
    "    def is_up(tip, base):\n",
    "        return tip.y < base.y\n",
    "\n",
    "    fingers = [is_up(tips[i], bases[i]) for i in range(5)]\n",
    "\n",
    "    if fingers == [False, False, False, False, False]:\n",
    "        return \"fist\"\n",
    "    elif fingers == [False, True, True, False, False]:\n",
    "        return \"victory\"\n",
    "    elif fingers == [True, True, True, True, True]:\n",
    "        return \"palm\"\n",
    "    elif fingers == [True, False, False, False, False]:\n",
    "        return \"thumbs_up\"\n",
    "    elif fingers[0] and fingers[1] and abs(landmarks[4].x - landmarks[8].x) < 0.05:\n",
    "        return \"rock_on\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Launch application safely\n",
    "def launch_app(app_path):\n",
    "    try:\n",
    "        subprocess.Popen(app_path, shell=True)\n",
    "        print(f\"Launching {app_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error launching {app_path}: {e}\")\n",
    "\n",
    "# Camera + gesture detection\n",
    "def run_camera():\n",
    "    global camera_running\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_gesture = None\n",
    "\n",
    "    while camera_running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        gesture = None\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = detect_gesture(hand_landmarks.landmark)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if gesture and gesture != last_gesture:\n",
    "            last_gesture = gesture\n",
    "            if gesture in GESTURE_ACTIONS:\n",
    "                if current_time - last_launched[gesture] > COOLDOWN_SECONDS:\n",
    "                    print(f\"Detected gesture: {gesture}\")\n",
    "                    launch_app(GESTURE_ACTIONS[gesture])\n",
    "                    last_launched[gesture] = current_time\n",
    "                else:\n",
    "                    print(f\"Gesture '{gesture}' is on cooldown.\")\n",
    "        elif gesture is None:\n",
    "            last_gesture = None\n",
    "\n",
    "        cv2.putText(frame, f\"Gesture: {gesture or 'None'}\", (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Sign Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Esc key to stop\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start camera detection\n",
    "def start_detection():\n",
    "    global camera_running\n",
    "    camera_running = True\n",
    "    threading.Thread(target=run_camera, daemon=True).start()\n",
    "\n",
    "# Stop camera detection\n",
    "def stop_detection():\n",
    "    global camera_running\n",
    "    camera_running = False\n",
    "    print(\"Camera stopped.\")\n",
    "\n",
    "# GUI\n",
    "root = Tk()\n",
    "root.title(\"Hand Sign App Launcher\")\n",
    "root.geometry(\"400x200\")\n",
    "\n",
    "label = Label(root, text=\"Click to Start Gesture Recognition\", font=(\"Arial\", 14))\n",
    "label.pack(pady=20)\n",
    "\n",
    "start_button = Button(root, text=\"Start\", command=start_detection, font=(\"Arial\", 14), bg=\"green\", fg=\"white\")\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "stop_button = Button(root, text=\"Stop\", command=stop_detection, font=(\"Arial\", 14), bg=\"red\", fg=\"white\")\n",
    "stop_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f8628-a179-4ccb-8a18-9a81e20aa704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (handsign)",
   "language": "python",
   "name": "handsign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
